{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats.mstats import spearmanr\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from pavooc.scoring.feature_extraction import extract_features, split_test_train_valid, normalize_features\n",
    "from pavooc.scoring.azimuth_dataset import load_dataset\n",
    "from pavooc.scoring import models\n",
    "from pavooc.scoring.helper import run_model, run_models, train_predict_n_shuffles\n",
    "from pavooc.scoring.training import cv_train_test\n",
    "from pavooc.config import CONSERVATION_FEATURES_FILE, SCALER_FILE\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 149 samples for gene CCDC101 \ttotal number of samples: 149\n",
      "Loaded 924 samples for gene MED12 \ttotal number of samples: 1073\n",
      "Loaded 190 samples for gene TADA2B \ttotal number of samples: 1263\n",
      "Loaded 109 samples for gene TADA1 \ttotal number of samples: 1372\n",
      "Loaded 64 samples for gene HPRT1 \ttotal number of samples: 1436\n",
      "Loaded 154 samples for gene CUL3 \ttotal number of samples: 1590\n",
      "Loaded 736 samples for gene NF1 \ttotal number of samples: 2326\n",
      "Loaded 223 samples for gene NF2 \ttotal number of samples: 2549\n",
      "Loaded 924 samples for gene MED12 \ttotal number of samples: 3473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/moritz/Projects/credit/pavooc/../data/scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf, Y, gene_position, target_genes = load_dataset()\n",
    "conservation_scores = pd.read_csv(CONSERVATION_FEATURES_FILE, index_col=0)\n",
    "\n",
    "combined_features, y, genes, feature_names = extract_features(Xdf, Y, gene_position, conservation_scores, order=1)\n",
    "normalized_features, scaler = normalize_features(combined_features)\n",
    "X_train, X_test, y_train, y_test, validation_fold, _ = split_test_train_valid(combined_features, y, joint_scaling=True)\n",
    "\n",
    "joblib.dump(scaler, SCALER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/moritz/Projects/credit/pavooc/../data/scaler.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from pavooc.config import CONSERVATION_FEATURES_FILE, SCALER_FILE\n",
    "joblib.dump(scaler, SCALER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>30mer</th>\n",
       "      <th>Strand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sequence</th>\n",
       "      <th>Target</th>\n",
       "      <th>drug</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAAAAAAACACTGCAACAAG</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CAGAAAAAAAAACACTGCAACAAGAGGGTA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAGCAGCGTCAGTGGAT</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TCAGAAAAAGCAGCGTCAGTGGATTGGCCC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAACAACGGCCCAGGAGGG</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCAGAAAACAACGGCCCAGGAGGGCGGCCA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAGGAAGATTGCTGATGA</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>ATACAAAAGGAAGATTGCTGATGAGGGCAG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAGTATCAGTGTGTATAG</th>\n",
       "      <th>THY1</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CAATAAAAGTATCAGTGTGTATAGAGGTGA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACACAAGTGGGAGCAGGC</th>\n",
       "      <th>H2-K</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CACCAAACACAAGTGGGAGCAGGCTGGTGA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGTGACGTTCCGTCTC</th>\n",
       "      <th>CD28</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>AACGAAACAGTGACGTTCCGTCTCTGGAAT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACAGTGTGCAGTTCCAGT</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TGGAAAACAGTGTGCAGTTCCAGTTGGAGG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACGCCTAAGCCTAGTTGT</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCAGAAACGCCTAAGCCTAGTTGTGGGGAT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACTGATGGGCTGGCATTC</th>\n",
       "      <th>CD43</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>ACAGAAACTGATGGGCTGGCATTCTGGGCT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGACTTCTGTGTCCAGAA</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TGACAAAGACTTCTGTGTCCAGAAGGGCAA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGAGGAGGAGAAGGTGCA</th>\n",
       "      <th>CD43</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCCCAAAGAGGAGGAGAAGGTGCAAGGCCA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGCAGACTTATGGAGACA</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>AAGGAAAGCAGACTTATGGAGACATGGAAG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGCAGCCAGGACAGCAGT</th>\n",
       "      <th>CD33</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>GAGGAAAGCAGCCAGGACAGCAGTGGGCAG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGCAGTCGCCCCTGCTTG</th>\n",
       "      <th>CD28</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TGGTAAAGCAGTCGCCCCTGCTTGTGGTAG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGGCCACAGTTATTGTCA</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>AGCAAAAGGCCACAGTTATTGTCATGGTCA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGTAGTCGCCCTCATCCT</th>\n",
       "      <th>THY1</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CACAAAAGTAGTCGCCCTCATCCTTGGTGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGTCTCTGGCAGGGGCGT</th>\n",
       "      <th>CD28</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CTGCAAAGTCTCTGGCAGGGGCGTAGGGCT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAATAATACCAACAACTGGA</th>\n",
       "      <th>CD13</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TCAGAAATAATACCAACAACTGGAGGGAGA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAATGATGATTGCTGCTCAG</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCAGAAATGATGATTGCTGCTCAGGGGCCA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAATGCTAAGTGTGGAAATG</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TCCAAAATGCTAAGTGTGGAAATGAGGATT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAATTTCTGGCTGCAAGTGC</th>\n",
       "      <th>CD33</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>ATCCAAATTTCTGGCTGCAAGTGCAGGAGT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAAAATGTCAGAATGGAT</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TTCCAACAAAATGTCAGAATGGATTGGCTC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAACAGGAACTCGTTGAA</th>\n",
       "      <th>CD45</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>GATGAACAACAGGAACTCGTTGAAAGGGGT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACACTGAGACAGCTTCTCC</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>TGGTAACACTGAGACAGCTTCTCCTGGGCA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAGCAACGGTCGCCATGT</th>\n",
       "      <th>H2-K</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCAGAACAGCAACGGTCGCCATGTTGGAGA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAGCAGGAGCAGCGTGCA</th>\n",
       "      <th>H2-K</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CGCCAACAGCAGGAGCAGCGTGCACGGTAC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAGCTCACTGATCTGGGC</th>\n",
       "      <th>CD13</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>GTCAAACAGCTCACTGATCTGGGCCGGCGT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACATGACTCCCCGGAGGCC</th>\n",
       "      <th>CD28</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CATGAACATGACTCCCCGGAGGCCTGGGCT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACCCAGCGGGCCTGGCCCC</th>\n",
       "      <th>CD5</th>\n",
       "      <th>nodrug</th>\n",
       "      <td>CCCAAACCCAGCGGGCCTGGCCCCAGGCAC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCGCTTTATGCGCTGCCGCT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GAATGCGCTTTATGCGCTGCCGCTGGGGGT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCGGCCCCTGAAGCGGCCG</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GAACACCGGCCCCTGAAGCGGCCGCGGCTG</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACAGACAGCAGCTTTGGTC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>CAGCAACAGACAGCAGCTTTGGTCCGGCAA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCTGGGTCTGCTGAAGCCCC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>TGCTGCTGGGTCTGCTGAAGCCCCTGGCGC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TACTCAACACTGGGTCTTGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GCACTACTCAACACTGGGTCTTGCAGGTCA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCCCCAGCCGCGGCCGCTTC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GGAGGCCCCAGCCGCGGCCGCTTCAGGGGC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCCAGCAGCTACCTGGGGCT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GTAGTCCAGCAGCTACCTGGGGCTGGGACT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTAAGGCTGGCTGGAGTAGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>TCTGGTAAGGCTGGCTGGAGTAGCTGGGGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGCCCCTGGCGCTGGAACT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GCTGAAGCCCCTGGCGCTGGAACTGGGTGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCAGCAACAGACAGCAGCTT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AGCAGCAGCAACAGACAGCAGCTTTGGTCC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCAGGCGGCTCCTCATCTTC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AGGAGCAGGCGGCTCCTCATCTTCTGGGGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCCTGTCTCTGCTGACTGT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GATGACCCTGTCTCTGCTGACTGTTGGAAA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGCTACCTGGGGCTGGGACT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>CAGCAGCTACCTGGGGCTGGGACTGGGGCT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGCAATAATGCTGCTGAAGT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>TCTCTGCAATAATGCTGCTGAAGTTGGAAC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCTGCTAGAGCCTGAGAAAA</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>CTACCCTGCTAGAGCCTGAGAAAAAGGCTC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGGCGCGGGGCCGGGGCCTC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>TAATAGGCGCGGGGCCGGGGCCTCAGGTGT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGGCCCCGCGCCTATTACC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GGCCCCGGCCCCGCGCCTATTACCTGGAGC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCCCAAATTTGTTCTTTAAA</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AGCTCCCCAAATTTGTTCTTTAAATGGCTA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGCCACTGGGCCGCTGTTGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>ACATAGCCACTGGGCCGCTGTTGCAGGTGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAGTGTTCTCTTTGAGGACA</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GTTCCAGTGTTCTCTTTGAGGACATGGAGA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGCTGTCTGTTGCTGCTGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AAAGCTGCTGTCTGTTGCTGCTGCTGGGTC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCCCGAGGGGACCTTGCCTT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>CATCTCCCGAGGGGACCTTGCCTTTGGAGC</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTCACCTCTGTCTTGGTAGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GGCGCTCACCTCTGTCTTGGTAGCTGGCTG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCAGTTCATCTTCGACCTCA</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>ATGTGCAGTTCATCTTCGACCTCATGGAAT</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGACGCCTGCCTGGACGCCC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GAACGGACGCCTGCCTGGACGCCCTGGGCA</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGCTGTCTGTTGCTGCTGCT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AAGCTGCTGTCTGTTGCTGCTGCTGGGTCT</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATCCCAGTGCCTTACCCGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>ATGAAATCCCAGTGCCTTACCCGCAGGATC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCAGGTCCGTGCAAAGTTGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>CATTGCAGGTCCGTGCAAAGTTGCGGGAGA</td>\n",
       "      <td>sense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGCGCTTTATGCGCTGCCGC</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>AGAATGCGCTTTATGCGCTGCCGCTGGGGG</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGCTGTTGCAGGTGGCGGGT</th>\n",
       "      <th>MED12</th>\n",
       "      <th>PLX_2uM</th>\n",
       "      <td>GGGCCGCTGTTGCAGGTGGCGGGTAGGATC</td>\n",
       "      <td>antisense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5304 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              30mer     Strand\n",
       "Sequence             Target drug                                              \n",
       "AAAAAAAACACTGCAACAAG CD5    nodrug   CAGAAAAAAAAACACTGCAACAAGAGGGTA      sense\n",
       "AAAAAGCAGCGTCAGTGGAT CD5    nodrug   TCAGAAAAAGCAGCGTCAGTGGATTGGCCC      sense\n",
       "AAAACAACGGCCCAGGAGGG CD5    nodrug   CCAGAAAACAACGGCCCAGGAGGGCGGCCA      sense\n",
       "AAAAGGAAGATTGCTGATGA CD45   nodrug   ATACAAAAGGAAGATTGCTGATGAGGGCAG      sense\n",
       "AAAAGTATCAGTGTGTATAG THY1   nodrug   CAATAAAAGTATCAGTGTGTATAGAGGTGA      sense\n",
       "AAACACAAGTGGGAGCAGGC H2-K   nodrug   CACCAAACACAAGTGGGAGCAGGCTGGTGA      sense\n",
       "AAACAGTGACGTTCCGTCTC CD28   nodrug   AACGAAACAGTGACGTTCCGTCTCTGGAAT      sense\n",
       "AAACAGTGTGCAGTTCCAGT CD5    nodrug   TGGAAAACAGTGTGCAGTTCCAGTTGGAGG      sense\n",
       "AAACGCCTAAGCCTAGTTGT CD45   nodrug   CCAGAAACGCCTAAGCCTAGTTGTGGGGAT      sense\n",
       "AAACTGATGGGCTGGCATTC CD43   nodrug   ACAGAAACTGATGGGCTGGCATTCTGGGCT  antisense\n",
       "AAAGACTTCTGTGTCCAGAA CD45   nodrug   TGACAAAGACTTCTGTGTCCAGAAGGGCAA  antisense\n",
       "AAAGAGGAGGAGAAGGTGCA CD43   nodrug   CCCCAAAGAGGAGGAGAAGGTGCAAGGCCA  antisense\n",
       "AAAGCAGACTTATGGAGACA CD45   nodrug   AAGGAAAGCAGACTTATGGAGACATGGAAG      sense\n",
       "AAAGCAGCCAGGACAGCAGT CD33   nodrug   GAGGAAAGCAGCCAGGACAGCAGTGGGCAG      sense\n",
       "AAAGCAGTCGCCCCTGCTTG CD28   nodrug   TGGTAAAGCAGTCGCCCCTGCTTGTGGTAG      sense\n",
       "AAAGGCCACAGTTATTGTCA CD45   nodrug   AGCAAAAGGCCACAGTTATTGTCATGGTCA      sense\n",
       "AAAGTAGTCGCCCTCATCCT THY1   nodrug   CACAAAAGTAGTCGCCCTCATCCTTGGTGG  antisense\n",
       "AAAGTCTCTGGCAGGGGCGT CD28   nodrug   CTGCAAAGTCTCTGGCAGGGGCGTAGGGCT  antisense\n",
       "AAATAATACCAACAACTGGA CD13   nodrug   TCAGAAATAATACCAACAACTGGAGGGAGA      sense\n",
       "AAATGATGATTGCTGCTCAG CD45   nodrug   CCAGAAATGATGATTGCTGCTCAGGGGCCA      sense\n",
       "AAATGCTAAGTGTGGAAATG CD45   nodrug   TCCAAAATGCTAAGTGTGGAAATGAGGATT      sense\n",
       "AAATTTCTGGCTGCAAGTGC CD33   nodrug   ATCCAAATTTCTGGCTGCAAGTGCAGGAGT      sense\n",
       "AACAAAATGTCAGAATGGAT CD45   nodrug   TTCCAACAAAATGTCAGAATGGATTGGCTC  antisense\n",
       "AACAACAGGAACTCGTTGAA CD45   nodrug   GATGAACAACAGGAACTCGTTGAAAGGGGT      sense\n",
       "AACACTGAGACAGCTTCTCC CD5    nodrug   TGGTAACACTGAGACAGCTTCTCCTGGGCA  antisense\n",
       "AACAGCAACGGTCGCCATGT H2-K   nodrug   CCAGAACAGCAACGGTCGCCATGTTGGAGA  antisense\n",
       "AACAGCAGGAGCAGCGTGCA H2-K   nodrug   CGCCAACAGCAGGAGCAGCGTGCACGGTAC  antisense\n",
       "AACAGCTCACTGATCTGGGC CD13   nodrug   GTCAAACAGCTCACTGATCTGGGCCGGCGT  antisense\n",
       "AACATGACTCCCCGGAGGCC CD28   nodrug   CATGAACATGACTCCCCGGAGGCCTGGGCT      sense\n",
       "AACCCAGCGGGCCTGGCCCC CD5    nodrug   CCCAAACCCAGCGGGCCTGGCCCCAGGCAC      sense\n",
       "...                                                             ...        ...\n",
       "GCGCTTTATGCGCTGCCGCT MED12  PLX_2uM  GAATGCGCTTTATGCGCTGCCGCTGGGGGT  antisense\n",
       "ACCGGCCCCTGAAGCGGCCG MED12  PLX_2uM  GAACACCGGCCCCTGAAGCGGCCGCGGCTG      sense\n",
       "AACAGACAGCAGCTTTGGTC MED12  PLX_2uM  CAGCAACAGACAGCAGCTTTGGTCCGGCAA      sense\n",
       "GCTGGGTCTGCTGAAGCCCC MED12  PLX_2uM  TGCTGCTGGGTCTGCTGAAGCCCCTGGCGC  antisense\n",
       "TACTCAACACTGGGTCTTGC MED12  PLX_2uM  GCACTACTCAACACTGGGTCTTGCAGGTCA  antisense\n",
       "GCCCCAGCCGCGGCCGCTTC MED12  PLX_2uM  GGAGGCCCCAGCCGCGGCCGCTTCAGGGGC  antisense\n",
       "TCCAGCAGCTACCTGGGGCT MED12  PLX_2uM  GTAGTCCAGCAGCTACCTGGGGCTGGGACT  antisense\n",
       "GTAAGGCTGGCTGGAGTAGC MED12  PLX_2uM  TCTGGTAAGGCTGGCTGGAGTAGCTGGGGG  antisense\n",
       "AAGCCCCTGGCGCTGGAACT MED12  PLX_2uM  GCTGAAGCCCCTGGCGCTGGAACTGGGTGG  antisense\n",
       "GCAGCAACAGACAGCAGCTT MED12  PLX_2uM  AGCAGCAGCAACAGACAGCAGCTTTGGTCC      sense\n",
       "GCAGGCGGCTCCTCATCTTC MED12  PLX_2uM  AGGAGCAGGCGGCTCCTCATCTTCTGGGGG  antisense\n",
       "ACCCTGTCTCTGCTGACTGT MED12  PLX_2uM  GATGACCCTGTCTCTGCTGACTGTTGGAAA  antisense\n",
       "AGCTACCTGGGGCTGGGACT MED12  PLX_2uM  CAGCAGCTACCTGGGGCTGGGACTGGGGCT  antisense\n",
       "TGCAATAATGCTGCTGAAGT MED12  PLX_2uM  TCTCTGCAATAATGCTGCTGAAGTTGGAAC  antisense\n",
       "CCTGCTAGAGCCTGAGAAAA MED12  PLX_2uM  CTACCCTGCTAGAGCCTGAGAAAAAGGCTC      sense\n",
       "AGGCGCGGGGCCGGGGCCTC MED12  PLX_2uM  TAATAGGCGCGGGGCCGGGGCCTCAGGTGT  antisense\n",
       "CCGGCCCCGCGCCTATTACC MED12  PLX_2uM  GGCCCCGGCCCCGCGCCTATTACCTGGAGC      sense\n",
       "CCCCAAATTTGTTCTTTAAA MED12  PLX_2uM  AGCTCCCCAAATTTGTTCTTTAAATGGCTA  antisense\n",
       "AGCCACTGGGCCGCTGTTGC MED12  PLX_2uM  ACATAGCCACTGGGCCGCTGTTGCAGGTGG  antisense\n",
       "CAGTGTTCTCTTTGAGGACA MED12  PLX_2uM  GTTCCAGTGTTCTCTTTGAGGACATGGAGA      sense\n",
       "CTGCTGTCTGTTGCTGCTGC MED12  PLX_2uM  AAAGCTGCTGTCTGTTGCTGCTGCTGGGTC  antisense\n",
       "TCCCGAGGGGACCTTGCCTT MED12  PLX_2uM  CATCTCCCGAGGGGACCTTGCCTTTGGAGC      sense\n",
       "CTCACCTCTGTCTTGGTAGC MED12  PLX_2uM  GGCGCTCACCTCTGTCTTGGTAGCTGGCTG  antisense\n",
       "GCAGTTCATCTTCGACCTCA MED12  PLX_2uM  ATGTGCAGTTCATCTTCGACCTCATGGAAT      sense\n",
       "GGACGCCTGCCTGGACGCCC MED12  PLX_2uM  GAACGGACGCCTGCCTGGACGCCCTGGGCA  antisense\n",
       "TGCTGTCTGTTGCTGCTGCT MED12  PLX_2uM  AAGCTGCTGTCTGTTGCTGCTGCTGGGTCT  antisense\n",
       "AATCCCAGTGCCTTACCCGC MED12  PLX_2uM  ATGAAATCCCAGTGCCTTACCCGCAGGATC  antisense\n",
       "GCAGGTCCGTGCAAAGTTGC MED12  PLX_2uM  CATTGCAGGTCCGTGCAAAGTTGCGGGAGA      sense\n",
       "TGCGCTTTATGCGCTGCCGC MED12  PLX_2uM  AGAATGCGCTTTATGCGCTGCCGCTGGGGG  antisense\n",
       "CGCTGTTGCAGGTGGCGGGT MED12  PLX_2uM  GGGCCGCTGTTGCAGGTGGCGGGTAGGATC  antisense\n",
       "\n",
       "[5304 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actually including non-order features as well\n",
    "order1_features = [not re.match('^[ACTG]{2}(_\\d+)?$', feature) for feature in feature_names]\n",
    "order2_features = [True for feature in feature_names]\n",
    "# without counts etc..\n",
    "pure_seq1_features = [bool(re.match('^([ACTG]_\\d{1,2})$', feature)) for feature in feature_names]\n",
    "pure_order1_features = [bool(re.match('^([ACTG]_\\d{1,2}|Percent Peptide|Amino Acid Cut position|conservation.*|.*False)$', feature)) for feature in feature_names]\n",
    "pure_order1_without_conservation_features = [bool(re.match('^([ACTG]_\\d{1,2}|Percent Peptide|Amino Acid Cut position|.*False)$', feature)) for feature in feature_names]\n",
    "order1_without_conservation_features = [not re.match('^([ACTG]{2}(_\\d+)?|conservation.*)$', feature) for feature in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pavooc.scoring.models import CNN34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be56d7cfb092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                     \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                     6000)\n\u001b[0m",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mtrain_predict_n_shuffles\u001b[0;34m(model_class, normalized_features, feature_selector, y, num_runs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 learning_rate, epochs, feature_selector, str(i))\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         predicted_labels = model(\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(combined_features, y, validation_fold, model_class, loss, learning_rate, epochs, feature_selector, postfix)\u001b[0m\n\u001b[1;32m     34\u001b[0m         combined_features[:,\n\u001b[1;32m     35\u001b[0m                           feature_selector], y, validation_fold, model_class,\n\u001b[0;32m---> 36\u001b[0;31m         learning_rate, loss, epochs, tensorboard_experiment)\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspearmans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/training.py\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(combined_features, y, validation_fold, model_class, learning_rate, loss, epochs, tensorboard_experiment)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn34_results = train_predict_n_shuffles(CNN34, \n",
    "                                                    normalized_features,\n",
    "                                                    order1_features,\n",
    "                                                    y,\n",
    "                                                    10,\n",
    "                                                    0.0003,\n",
    "                                                    6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {'model_class': CNN34, 'feature_selector': order1_features, 'loss': nn.MSELoss(), 'learning_rate': 0.0003, 'epochs': 6000},\n",
    "    ]\n",
    "\n",
    "results = run_models(X_train, y_train, validation_fold, configs)\n",
    "model = results[0][2]\n",
    "predicted_labels = model(torch.from_numpy(X_test)).cpu().data.numpy()\n",
    "\n",
    "print(spearmanr(predicted_labels, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "configs = [\n",
    "    {'model_class': CNN34, 'feature_selector': order1_features, 'loss': nn.MSELoss(), 'learning_rate': 0.00034, 'epochs': 6002},\n",
    "    ]\n",
    "\n",
    "results = run_models(X_train, y_train, validation_fold, configs)\n",
    "model = results[0][2]\n",
    "predicted_labels = model(torch.from_numpy(X_test[:, order1_features])).cpu().data.numpy()\n",
    "print(max(results[0][1]))\n",
    "print(spearmanr(predicted_labels, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14953672767542303,\n",
       " 0.2650470499313614,\n",
       " 0.3217276550514562,\n",
       " 0.33831311658932495,\n",
       " 0.3508942935301225,\n",
       " 0.36646051636198546,\n",
       " 0.3836740852749887,\n",
       " 0.39512237924158866,\n",
       " 0.40099445490624597,\n",
       " 0.41228947013063433,\n",
       " 0.4216424495389706,\n",
       " 0.42852516680969,\n",
       " 0.4375982906807524,\n",
       " 0.4418815746949079,\n",
       " 0.4457885990958921,\n",
       " 0.4561056624928287,\n",
       " 0.461232202652893,\n",
       " 0.4670785970821433,\n",
       " 0.4696364375696398,\n",
       " 0.475407277119418,\n",
       " 0.4763841654617514,\n",
       " 0.4800884742995758,\n",
       " 0.47904533531741794,\n",
       " 0.47406794211467357,\n",
       " 0.48671393331374685,\n",
       " 0.4897066503944287,\n",
       " 0.49412225790805375,\n",
       " 0.49966972819870403,\n",
       " 0.5054237841525172,\n",
       " 0.5084805580538745,\n",
       " 0.511505826041232,\n",
       " 0.5166478629491817,\n",
       " 0.5203193661908911,\n",
       " 0.5256366314879337,\n",
       " 0.527733020415568,\n",
       " 0.5281062034638453,\n",
       " 0.5302523889451308,\n",
       " 0.5431178898834079,\n",
       " 0.541215303869425,\n",
       " 0.5460441451052457,\n",
       " 0.5532296121094104,\n",
       " 0.558406284671186,\n",
       " 0.5614233073292159,\n",
       " 0.5674655674464576,\n",
       " 0.5692945077324174,\n",
       " 0.572757412044593,\n",
       " 0.5777268528445952,\n",
       " 0.5793355083362678,\n",
       " 0.5820780946166413,\n",
       " 0.5806419573803306,\n",
       " 0.5839581135170613,\n",
       " 0.5889293779849804,\n",
       " 0.5896057375161134,\n",
       " 0.589957667744146,\n",
       " 0.5891349774992372,\n",
       " 0.5941504464819829,\n",
       " 0.5987633021996325,\n",
       " 0.5988983433778469,\n",
       " 0.6026225464375992,\n",
       " 0.6039473615571653,\n",
       " 0.5980723247071726,\n",
       " 0.5965648619352274,\n",
       " 0.6074482509632235,\n",
       " 0.6052004984423079,\n",
       " 0.6080904028296175,\n",
       " 0.6114097342629645,\n",
       " 0.6089481873783547,\n",
       " 0.6080156445653805,\n",
       " 0.6068181664187908,\n",
       " 0.6107252992633085,\n",
       " 0.609905813009654,\n",
       " 0.6108734435570395,\n",
       " 0.6113574059036102,\n",
       " 0.613134252329217,\n",
       " 0.6135349713503582,\n",
       " 0.6100055296808585,\n",
       " 0.6115951375493309,\n",
       " 0.6118238989686947,\n",
       " 0.6143817686409141,\n",
       " 0.6157756761190522,\n",
       " 0.6181081565635154,\n",
       " 0.6163145058369144,\n",
       " 0.6144409719510078,\n",
       " 0.6162378301543682,\n",
       " 0.6180849059191643,\n",
       " 0.6231982961597772,\n",
       " 0.6150697098951501,\n",
       " 0.6167566112904981,\n",
       " 0.6179096451242503,\n",
       " 0.6164643679938807,\n",
       " 0.6163340723495423,\n",
       " 0.6194649662561251,\n",
       " 0.6168781060343316,\n",
       " 0.6197600911297825,\n",
       " 0.6199304351032803,\n",
       " 0.6215045434623762,\n",
       " 0.6217347774376913,\n",
       " 0.6256989458433105,\n",
       " 0.6263493560679175,\n",
       " 0.6232898098494265,\n",
       " 0.6207783592960414,\n",
       " 0.6206817826893579,\n",
       " 0.622317344658807,\n",
       " 0.6246391048306461,\n",
       " 0.6208687980467958,\n",
       " 0.6219660224285025,\n",
       " 0.6162352272042607,\n",
       " 0.6197640608547955,\n",
       " 0.6213362668660828,\n",
       " 0.6167782014138312,\n",
       " 0.6181445289170618,\n",
       " 0.6174929131214948,\n",
       " 0.6200957041759402,\n",
       " 0.6178678773703372,\n",
       " 0.619161468688341,\n",
       " 0.617575649186886,\n",
       " 0.6169546088821093,\n",
       " 0.6203653986284476,\n",
       " 0.6176989575106746,\n",
       " 0.6153567391493963,\n",
       " 0.6169973624754232,\n",
       " 0.6152959086550649,\n",
       " 0.6152881959025331,\n",
       " 0.614762242602353,\n",
       " 0.6112082959071605,\n",
       " 0.6136054204015832,\n",
       " 0.6172017579735839,\n",
       " 0.6172886753475829,\n",
       " 0.6179361838442616,\n",
       " 0.6209283741483248,\n",
       " 0.6206228413408132,\n",
       " 0.6158990398577838,\n",
       " 0.617853655880855,\n",
       " 0.6179117257034767,\n",
       " 0.6184173114932153,\n",
       " 0.6166742480186043,\n",
       " 0.6142748918193359,\n",
       " 0.6176910885887579,\n",
       " 0.6148372728865888,\n",
       " 0.6182203633050114,\n",
       " 0.6142710158678563,\n",
       " 0.6172493559266093,\n",
       " 0.6169815541035202,\n",
       " 0.6127124438579654,\n",
       " 0.6159107827879938,\n",
       " 0.6149061904735765,\n",
       " 0.6124509190480222,\n",
       " 0.6159801219949486,\n",
       " 0.6133680117361282,\n",
       " 0.6150893973131084,\n",
       " 0.6186634697080818,\n",
       " 0.6158472656365511,\n",
       " 0.6183946905633462,\n",
       " 0.6192595493014557,\n",
       " 0.6154461753800222,\n",
       " 0.6158369534194428,\n",
       " 0.6175307026303292,\n",
       " 0.617579407327571,\n",
       " 0.6181418120278381,\n",
       " 0.6172233512051403,\n",
       " 0.6165937064710204,\n",
       " 0.618116064230261,\n",
       " 0.6132194417545057,\n",
       " 0.6186664721904521,\n",
       " 0.6188285171181939,\n",
       " 0.6215848110542465,\n",
       " 0.6189685909814768,\n",
       " 0.6156328969993553,\n",
       " 0.6181351521592416,\n",
       " 0.6179696846962124,\n",
       " 0.6192828475645662,\n",
       " 0.6153520036906243,\n",
       " 0.6150276801796879,\n",
       " 0.6131968344062811,\n",
       " 0.6109290650467218,\n",
       " 0.6141907014078489,\n",
       " 0.6093844223507401,\n",
       " 0.6105897140107674,\n",
       " 0.6139337035620885,\n",
       " 0.6118455894445786,\n",
       " 0.6144739539175823,\n",
       " 0.6166414388878975,\n",
       " 0.6153671029061253,\n",
       " 0.6153554762311444,\n",
       " 0.6160836638490541,\n",
       " 0.6164719761277543,\n",
       " 0.6182641744511271,\n",
       " 0.6142541329138433,\n",
       " 0.6179884300601383,\n",
       " 0.6168244799063829,\n",
       " 0.6163015100662795,\n",
       " 0.618528510691068,\n",
       " 0.6201646236898525,\n",
       " 0.6160588666290597,\n",
       " 0.6163360777744178,\n",
       " 0.6123830233045738,\n",
       " 0.615019504335041,\n",
       " 0.6131137595363532,\n",
       " 0.6152059012239609,\n",
       " 0.6120294290830696,\n",
       " 0.6138421844117469,\n",
       " 0.6142208401556355,\n",
       " 0.6148695511207589,\n",
       " 0.6152030417363029,\n",
       " 0.6128394703440682,\n",
       " 0.6146029207579613,\n",
       " 0.6134230347107532,\n",
       " 0.6099131746579252,\n",
       " 0.608693434371509,\n",
       " 0.6073330469892096,\n",
       " 0.6095470078263218,\n",
       " 0.6079768788503426,\n",
       " 0.6090006504429928,\n",
       " 0.6104253292135763,\n",
       " 0.6090075076543546,\n",
       " 0.611913426469355,\n",
       " 0.6104016765197466,\n",
       " 0.6087119368295941,\n",
       " 0.6103568111546332,\n",
       " 0.6078270628706711,\n",
       " 0.6094184929396746,\n",
       " 0.6082705439572119,\n",
       " 0.6129934882983593,\n",
       " 0.6089582089414881,\n",
       " 0.6095726618741736,\n",
       " 0.6069486767047667,\n",
       " 0.6095647653652654,\n",
       " 0.6124831267480719,\n",
       " 0.6098431288815228,\n",
       " 0.6106089274592429,\n",
       " 0.6128823401409215,\n",
       " 0.6048700657602163,\n",
       " 0.6096611823294672,\n",
       " 0.6092925811741289,\n",
       " 0.6135625958702221,\n",
       " 0.6130133045060158,\n",
       " 0.6129194139580524,\n",
       " 0.6120646245642221,\n",
       " 0.6116817320797128,\n",
       " 0.6084774165007274,\n",
       " 0.6121636153918362,\n",
       " 0.6117692675397667,\n",
       " 0.6133059224133575,\n",
       " 0.616381009631553,\n",
       " 0.6127907489888983,\n",
       " 0.6155866344393571,\n",
       " 0.6192716828979627,\n",
       " 0.6169608863110617,\n",
       " 0.6164321963756609,\n",
       " 0.6130012769442041,\n",
       " 0.6155779970684317,\n",
       " 0.6131467868440904,\n",
       " 0.6147267177420407,\n",
       " 0.6180137845478064,\n",
       " 0.6155426206330382,\n",
       " 0.6137710114732315,\n",
       " 0.612277959244935,\n",
       " 0.6150074033482441,\n",
       " 0.6149212168255357,\n",
       " 0.6164378106757019,\n",
       " 0.6181862730400979,\n",
       " 0.6159221622529005,\n",
       " 0.6165626144846065,\n",
       " 0.6153109373418907,\n",
       " 0.6161263880307349,\n",
       " 0.6130722876395439,\n",
       " 0.6145188029699706,\n",
       " 0.6177742474540536,\n",
       " 0.6143475024165957,\n",
       " 0.6134461418742052,\n",
       " 0.6145750824359084,\n",
       " 0.61380317533181,\n",
       " 0.6149511881605491,\n",
       " 0.6143429642196496,\n",
       " 0.6177435644679231,\n",
       " 0.6169907574849933,\n",
       " 0.6177872249956707,\n",
       " 0.6160071455866353,\n",
       " 0.6150070268668345,\n",
       " 0.6134741481179434,\n",
       " 0.6146592017730492,\n",
       " 0.6163328087040926,\n",
       " 0.6116998695675849,\n",
       " 0.615852490153653,\n",
       " 0.6174502208611832,\n",
       " 0.614201842509101,\n",
       " 0.610703562436077,\n",
       " 0.6127009484159721,\n",
       " 0.6108172533230478,\n",
       " 0.608335288452392,\n",
       " 0.6125152634806744,\n",
       " 0.6135464142450773,\n",
       " 0.6161091376758312,\n",
       " 0.6118642784500925,\n",
       " 0.6094008026224951,\n",
       " 0.6116635957424934,\n",
       " 0.6114922481263559,\n",
       " 0.6115099704355446,\n",
       " 0.6170465723417222,\n",
       " 0.6148983966626056,\n",
       " 0.6175025231559317,\n",
       " 0.6144793790313465,\n",
       " 0.6141990753537395,\n",
       " 0.6129996436768291,\n",
       " 0.6118688627774326,\n",
       " 0.6180334068224583,\n",
       " 0.6170283475216697,\n",
       " 0.6137249843889816,\n",
       " 0.6127574962066863,\n",
       " 0.6161745744561484,\n",
       " 0.6123663077471365,\n",
       " 0.611812092386724,\n",
       " 0.6129423313714465,\n",
       " 0.6084640962025311,\n",
       " 0.6101572969922394,\n",
       " 0.6123688874297968,\n",
       " 0.6139558283941243,\n",
       " 0.6138976593605994,\n",
       " 0.6136840752793673,\n",
       " 0.6121800530594631,\n",
       " 0.6130895030826244,\n",
       " 0.6128163627896739,\n",
       " 0.6145258387543072,\n",
       " 0.6111766126964606,\n",
       " 0.6113284058678058,\n",
       " 0.6121343270713385,\n",
       " 0.6098628975246099,\n",
       " 0.6103421356095386,\n",
       " 0.607357097538333,\n",
       " 0.6070578778658666,\n",
       " 0.6094053797484265,\n",
       " 0.6068445493141554,\n",
       " 0.609303688121393,\n",
       " 0.6120050259143738,\n",
       " 0.613447348916783,\n",
       " 0.6136668545653186,\n",
       " 0.6116984114416655,\n",
       " 0.6113660023931252,\n",
       " 0.6131825281274832,\n",
       " 0.6131219060291772,\n",
       " 0.6095459370974721,\n",
       " 0.6097922308716526,\n",
       " 0.6125933493333162,\n",
       " 0.6095406953736189,\n",
       " 0.6052548451218375,\n",
       " 0.6100587234952155,\n",
       " 0.6104910909975385,\n",
       " 0.610348171027528,\n",
       " 0.6126165045708184,\n",
       " 0.6125456189098625,\n",
       " 0.6151019334665742,\n",
       " 0.6139428023905923,\n",
       " 0.6109885247103902,\n",
       " 0.6105402266665608,\n",
       " 0.611724928914274,\n",
       " 0.6146502453043335,\n",
       " 0.6112417407956015,\n",
       " 0.6148420766929098,\n",
       " 0.6149041770269021,\n",
       " 0.6150100493529896,\n",
       " 0.6123801467243765,\n",
       " 0.613641853037193,\n",
       " 0.6143638051424638,\n",
       " 0.6155053329799642,\n",
       " 0.6134861378971402,\n",
       " 0.6130259370962275,\n",
       " 0.6087187576991038,\n",
       " 0.6079764043929091,\n",
       " 0.60991164927497,\n",
       " 0.6091135765982737,\n",
       " 0.6063240080298418,\n",
       " 0.6104910935726268,\n",
       " 0.6086053002949942,\n",
       " 0.6116200172871994,\n",
       " 0.6104496255011023,\n",
       " 0.612882825871515,\n",
       " 0.6102297742400193,\n",
       " 0.6149504817354622,\n",
       " 0.616531507702761,\n",
       " 0.6159602734139333,\n",
       " 0.6132038317758906,\n",
       " 0.6147199718177767,\n",
       " 0.6116700626879618,\n",
       " 0.6157382520940122,\n",
       " 0.6109066663263857,\n",
       " 0.6114370644815081,\n",
       " 0.6128402666276062,\n",
       " 0.6082681152841137,\n",
       " 0.6095024792958277,\n",
       " 0.6135458844111656,\n",
       " 0.6114258266608522,\n",
       " 0.6097374705181424,\n",
       " 0.6102501268442894,\n",
       " 0.6132774940434649,\n",
       " 0.6091629265557124,\n",
       " 0.6120918691367714,\n",
       " 0.6086659796607196,\n",
       " 0.6125982596184054,\n",
       " 0.611855778338827,\n",
       " 0.6087792779403687,\n",
       " 0.6130629800030358,\n",
       " 0.613289399923663,\n",
       " 0.6143479724602404,\n",
       " 0.6164217538286227,\n",
       " 0.6144711312510099,\n",
       " 0.6154305848021276,\n",
       " 0.6159795243757104,\n",
       " 0.6141886268601902,\n",
       " 0.6136096443542268,\n",
       " 0.6106502024347201,\n",
       " 0.6143093775852415,\n",
       " 0.6103291065919375,\n",
       " 0.6104860180673575,\n",
       " 0.6119778418043953,\n",
       " 0.6110263543575535,\n",
       " 0.6110794141739059,\n",
       " 0.6112981546354066,\n",
       " 0.6093163178551965,\n",
       " 0.6101227464923056,\n",
       " 0.6091536617565401,\n",
       " 0.6089711833037054,\n",
       " 0.6084077105929808,\n",
       " 0.6091638969351811,\n",
       " 0.6065615303210655,\n",
       " 0.6124030449697808,\n",
       " 0.6091922355980438,\n",
       " 0.6114228710571843,\n",
       " 0.6139993596147539,\n",
       " 0.6120288038827588,\n",
       " 0.6122433372414073,\n",
       " 0.6087212014231348,\n",
       " 0.6106143267378299,\n",
       " 0.6108397129561356,\n",
       " 0.611646319288374,\n",
       " 0.6079633034235764,\n",
       " 0.6100512147829511,\n",
       " 0.6105331823393276,\n",
       " 0.6072028514002723,\n",
       " 0.6067447620546396,\n",
       " 0.6085561521437235,\n",
       " 0.6107446208742955,\n",
       " 0.6116898977433707,\n",
       " 0.6159498737433163,\n",
       " 0.6129076659915691,\n",
       " 0.6134487133144975,\n",
       " 0.6085604998301212,\n",
       " 0.6152745700112782,\n",
       " 0.6117445051177146,\n",
       " 0.6114420396646416,\n",
       " 0.6143586212377774,\n",
       " 0.6149095249144816,\n",
       " 0.6164215225779698,\n",
       " 0.61407681588059,\n",
       " 0.6139347954574091,\n",
       " 0.61338236606037,\n",
       " 0.613723571490311,\n",
       " 0.6125198377666751,\n",
       " 0.614358997312909,\n",
       " 0.6138935873346268,\n",
       " 0.6167792033778882,\n",
       " 0.6188953970316811,\n",
       " 0.6207562103571337,\n",
       " 0.6147655401871729,\n",
       " 0.6140595148457093,\n",
       " 0.6124485194579129,\n",
       " 0.6159555672121956,\n",
       " 0.6123736930487739,\n",
       " 0.6135302699882589,\n",
       " 0.6147705211936451,\n",
       " 0.6192578554697128,\n",
       " 0.6158556659464003,\n",
       " 0.6137287779772007,\n",
       " 0.610888882428853,\n",
       " 0.6102034069836643,\n",
       " 0.6099443395821382,\n",
       " 0.6110703066759597,\n",
       " 0.6118096058438424,\n",
       " 0.6110124209950885,\n",
       " 0.6098246153831508,\n",
       " 0.6130828901249104,\n",
       " 0.6137202342353123,\n",
       " 0.6107335782855529,\n",
       " 0.6148716594939652,\n",
       " 0.6119796050076625,\n",
       " 0.6116359743504781,\n",
       " 0.6116888196183079,\n",
       " 0.6111465698181459,\n",
       " 0.6138735345556139,\n",
       " 0.6109680078947222,\n",
       " 0.6140224159037831,\n",
       " 0.6130865492536524,\n",
       " 0.6152383606205108,\n",
       " 0.6156796207352622,\n",
       " 0.614156508047486,\n",
       " 0.6123681262510899,\n",
       " 0.6120270403769977,\n",
       " 0.6085914725166378,\n",
       " 0.6099407372684881,\n",
       " 0.609478116276855,\n",
       " 0.6100605175264638,\n",
       " 0.6092857427002735,\n",
       " 0.6068320898643869,\n",
       " 0.6090212934946299,\n",
       " 0.6113473411065269,\n",
       " 0.6074199292633803,\n",
       " 0.6070595240395246,\n",
       " 0.6061246173437573,\n",
       " 0.6083550386324218,\n",
       " 0.6107197404069864,\n",
       " 0.6107755400434436,\n",
       " 0.6092036614416543,\n",
       " 0.6140956994277761,\n",
       " 0.6106733883247967,\n",
       " 0.6138173817088057,\n",
       " 0.6115807271452701,\n",
       " 0.6134685065032781,\n",
       " 0.6128573449957523,\n",
       " 0.6113959941629894,\n",
       " 0.6092377517074339,\n",
       " 0.6074704196474819,\n",
       " 0.6077091657513312,\n",
       " 0.6111719549000526,\n",
       " 0.610780659907605,\n",
       " 0.6070579278046442,\n",
       " 0.6100202096030516,\n",
       " 0.6066741723858083,\n",
       " 0.6057115644231075,\n",
       " 0.6066332695075008,\n",
       " 0.6089944448408233,\n",
       " 0.6119404427592608,\n",
       " 0.6093204459165029,\n",
       " 0.6088897458614092,\n",
       " 0.6104904014705697,\n",
       " 0.6092236023966314,\n",
       " 0.60738996056283,\n",
       " 0.6076485518784394,\n",
       " 0.6076104163217745,\n",
       " 0.608938011179717,\n",
       " 0.6115052116910237,\n",
       " 0.6078012805008182,\n",
       " 0.6081940263572445,\n",
       " 0.6119287668607132,\n",
       " 0.6109580315278166,\n",
       " 0.6121589554988488,\n",
       " 0.6097656500036406,\n",
       " 0.6088064777892412,\n",
       " 0.6098772138613046,\n",
       " 0.6128840096590848,\n",
       " 0.6087904221315276,\n",
       " 0.6118295086212194,\n",
       " 0.6103685126711736,\n",
       " 0.6113740078599882,\n",
       " 0.610982672986545,\n",
       " 0.6117604720917992,\n",
       " 0.6106082035652923,\n",
       " 0.612058210306013,\n",
       " 0.6113413881910053,\n",
       " 0.6109083965277872,\n",
       " 0.6109662490259704,\n",
       " 0.6088519746658356,\n",
       " 0.6071181003370657,\n",
       " 0.6089691722356717,\n",
       " 0.6063240944237975,\n",
       " 0.606609016385114,\n",
       " 0.6076870400756545,\n",
       " 0.6079743453196224,\n",
       " 0.6085497214077964,\n",
       " 0.6092434276856961,\n",
       " 0.6050000593317795,\n",
       " 0.6075796084183511,\n",
       " 0.6078041989712035,\n",
       " 0.6071776473826698,\n",
       " 0.6090090284019755,\n",
       " 0.6054332011745699,\n",
       " 0.608378627977783,\n",
       " 0.6080538153857156,\n",
       " 0.6085975030006525,\n",
       " 0.6084085124154429,\n",
       " 0.6098735340540101,\n",
       " 0.6114762350025849,\n",
       " 0.6097150607678464,\n",
       " 0.6088951630584681,\n",
       " 0.6085962130132393,\n",
       " 0.6090867677855634,\n",
       " 0.6063466801394233,\n",
       " 0.6115341671225363,\n",
       " 0.6095071826658434,\n",
       " 0.6069953910509859,\n",
       " 0.6069324488476867,\n",
       " 0.6046617503838688,\n",
       " 0.6119999175425734,\n",
       " 0.6093180042734005,\n",
       " 0.6097259523231316,\n",
       " 0.6033882525743411,\n",
       " 0.6074375171074835,\n",
       " 0.6061169677166349,\n",
       " 0.6080704942963653,\n",
       " 0.6057827206508214,\n",
       " 0.6049460875687824,\n",
       " 0.6029747094383631]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx=model\n",
    "np.results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "configs = [\n",
    "    {'model_class': CNN34, 'feature_selector': order1_features, 'loss': nn.MSELoss(), 'learning_rate': 0.00029, 'epochs': 6000},\n",
    "    ]\n",
    "results = run_models(X_train, y_train, validation_fold, configs)\n",
    "model = results[0][2]\n",
    "predicted_labels = model(Variable(torch.from_numpy(X_test))).cpu().data.numpy()\n",
    "\n",
    "print(spearmanr(predicted_labels, y_test)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pavooc.scoring.models import CNN38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment CNN38_0.0003_6000_MSELoss_1600 already existed. Deleting.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-188ca16b6290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                     \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                     6000)\n\u001b[0m",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mtrain_predict_n_shuffles\u001b[0;34m(model_class, normalized_features, feature_selector, y, num_runs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 learning_rate, epochs, feature_selector, str(i))\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         predicted_labels = model(\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(combined_features, y, validation_fold, model_class, loss, learning_rate, epochs, feature_selector, postfix)\u001b[0m\n\u001b[1;32m     34\u001b[0m         combined_features[:,\n\u001b[1;32m     35\u001b[0m                           feature_selector], y, validation_fold, model_class,\n\u001b[0;32m---> 36\u001b[0;31m         learning_rate, loss, epochs, tensorboard_experiment)\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspearmans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/training.py\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(combined_features, y, validation_fold, model_class, learning_rate, loss, epochs, tensorboard_experiment)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mbatch_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-67ffb41a5cb4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mnuc_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mconvolution_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_convolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnuc_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# two fully connected hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-67ffb41a5cb4>\u001b[0m in \u001b[0;36m_forward_convolution\u001b[0;34m(self, nuc_features)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mconv1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mconv2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mconv2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mconv2_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 154\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     81\u001b[0m     f = ConvNd(_single(stride), _single(padding), _single(dilation), False,\n\u001b[1;32m     82\u001b[0m                _single(0), groups, torch.backends.cudnn.benchmark, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn38_results = train_predict_n_shuffles(CNN38, \n",
    "                                         normalized_features,\n",
    "                                         order1_features,\n",
    "                                         y,\n",
    "                                         9,\n",
    "                                         0.0003,\n",
    "                                         6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Experiment CNN38_0.0003_15000_MSELoss_160 already existed. Deleting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configs = [\n",
    "    {'model_class': CNN38, 'feature_selector': order1_features, 'loss': nn.MSELoss(), 'learning_rate': 0.0003, 'epochs': 15000},\n",
    "    ]\n",
    "results = run_models(X_train, y_train, validation_fold, configs)\n",
    "model = results[0][2]\n",
    "predicted_labels = model(Variable(torch.from_numpy(X_test[:, order1_features]))).cpu().data.numpy()\n",
    "\n",
    "print(spearmanr(predicted_labels, y_test)[0])\n",
    "print(max(results[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6332038254796858\n",
      "0.6324884048198914\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(predicted_labels, y_test)[0])\n",
    "print(max(results[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment CNN38_0.0003_3000_MSELoss_cv|0 already existed. Deleting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/lib/python3.6/site-packages/numpy/lib/function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/usr/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/usr/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "cv_result = cv_train_test(genes, normalized_features[:, order1_features], y, CNN38, 0.0003, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment CNN38_0.0003_6000_MSELoss_1600 already existed. Deleting.\n",
      "Experiment CNN38_0.0003_6000_MSELoss_1601 already existed. Deleting.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-40538ba78f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                 \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                 \u001b[0;36m0.0003\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                                 6000)\n\u001b[0m",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mtrain_predict_n_shuffles\u001b[0;34m(model_class, normalized_features, feature_selector, y, num_runs, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mmodel_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 learning_rate, epochs, feature_selector, str(i))\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         predicted_labels = model(\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/helper.py\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(combined_features, y, validation_fold, model_class, loss, learning_rate, epochs, feature_selector, postfix)\u001b[0m\n\u001b[1;32m     34\u001b[0m         combined_features[:,\n\u001b[1;32m     35\u001b[0m                           feature_selector], y, validation_fold, model_class,\n\u001b[0;32m---> 36\u001b[0;31m         learning_rate, loss, epochs, tensorboard_experiment)\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspearmans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/credit/pavooc/scoring/training.py\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(combined_features, y, validation_fold, model_class, learning_rate, loss, epochs, tensorboard_experiment)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         tensorboard_experiment.add_histogram_value(\n\u001b[1;32m    183\u001b[0m                             \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtobuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                             step=epoch_idx + 1)\n\u001b[0m\u001b[1;32m    185\u001b[0m                         tensorboard_experiment.add_histogram_value(\n\u001b[1;32m    186\u001b[0m                             \u001b[0;34m'{}/grad'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/pycrayon/crayon.py\u001b[0m in \u001b[0;36madd_histogram_value\u001b[0;34m(self, name, hist, tobuild, wall_time, step)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwall_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             raise ValueError(\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    506\u001b[0m         }\n\u001b[1;32m    507\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 )\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.6 and older, Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rand_shuffle_results = train_predict_n_shuffles(CNN38, \n",
    "                                                normalized_features,\n",
    "                                                order1_features,\n",
    "                                                y,\n",
    "                                                10,\n",
    "                                                0.0003,\n",
    "                                                6000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
